"The paper gives convergence theorems for several sequential Monte-Carlo or stochastic approximation algorithms for finding a local minimum of a function $f(\\bullet)$ on a set $C$ defined by $C = \\{x: q^i(x) \\leqq 0, i = 1, 2, \\cdots, s\\}. f(\\bullet)$ is unknown, but \"noise perturbed\" values can be observed at any desired parameter $x \\in C$. The algorithms generate a sequence of random variables $\\{X_n\\}$ such that (for a.a. $\\omega$) any convergent subsequence of $\\{X_n(\\omega)\\}$ converges to a point where a certain necessary condition for constrained optimality holds. The techniques are drawn from both stochastic approximation, and non-linear programming."
